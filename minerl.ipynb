{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_dict_single(current_state, action, reward, next_state, done):\n",
    "\n",
    "    equipments = {\"none\":1, 'air':2, 'wooden_axe':3, 'wooden_pickaxe':4, \n",
    "              'stone_axe':5, 'stone_pickaxe':6, 'iron_axe':7, 'iron_pickaxe':8}\n",
    "\n",
    "\n",
    "    # current state\n",
    "    mainhand = current_state['equipped_items']['mainhand']\n",
    "    inventory = current_state['inventory']\n",
    "    pov = current_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    \n",
    "    swap_world_state = np.swapaxes(pov,0,2)\n",
    "    \n",
    "     \n",
    "    # next_state\n",
    "    mainhand = next_state['equipped_items']['mainhand']\n",
    "    inventory = next_state['inventory']\n",
    "    pov = next_state['pov']\n",
    "\n",
    "\n",
    "    agent_state_next = []\n",
    "    agent_state_next.append(mainhand['damage'])\n",
    "    agent_state_next.append(mainhand['maxDamage'])\n",
    "    agent_state_next.append(mainhand['type'])\n",
    "    agent_state_next.append(inventory['coal'])\n",
    "    agent_state_next.append(inventory['cobblestone'])\n",
    "    agent_state_next.append(inventory['crafting_table'])\n",
    "    agent_state_next.append(inventory['dirt'])\n",
    "    agent_state_next.append(inventory['furnace'])\n",
    "    agent_state_next.append(inventory['iron_axe'])\n",
    "    agent_state_next.append(inventory['iron_ingot'])\n",
    "    agent_state_next.append(inventory['iron_ore'])\n",
    "    agent_state_next.append(inventory['iron_pickaxe'])\n",
    "    agent_state_next.append(inventory['log'])\n",
    "    agent_state_next.append(inventory['planks'])\n",
    "    agent_state_next.append(inventory['stick'])\n",
    "    agent_state_next.append(inventory['stone'])\n",
    "    agent_state_next.append(inventory['stone_axe'])\n",
    "    agent_state_next.append(inventory['stone_pickaxe'])\n",
    "    agent_state_next.append(inventory['torch'])\n",
    "    agent_state_next.append(inventory['wooden_axe'])\n",
    "    agent_state_next.append(inventory['wooden_pickaxe'])\n",
    "\n",
    " \n",
    "    swap_next_world_state = np.swapaxes(pov,0,2)\n",
    "    \n",
    "\n",
    "    \n",
    "    # get action list\n",
    "    \n",
    "    agent_actions = []\n",
    "    agent_actions.append(action[\"attack\"])\n",
    "    agent_actions.append(action[\"back\"])\n",
    "    agent_actions.append(action[\"camera\"][0])\n",
    "    agent_actions.append(action[\"camera\"][1])\n",
    "    agent_actions.append(action[\"craft\"])\n",
    "    agent_actions.append(action[\"equip\"])\n",
    "    agent_actions.append(action[\"forward\"])\n",
    "    agent_actions.append(action[\"jump\"])\n",
    "    agent_actions.append(action[\"left\"])\n",
    "    agent_actions.append(action[\"nearbyCraft\"])\n",
    "    agent_actions.append(action[\"nearbySmelt\"])\n",
    "    agent_actions.append(action[\"place\"])\n",
    "    agent_actions.append(action[\"right\"])\n",
    "    agent_actions.append(action[\"sneak\"])\n",
    "    agent_actions.append(action[\"sprint\"])\n",
    "    \n",
    "\n",
    "\n",
    "    experience = (np.array(agent_state), np.array(swap_world_state), np.array(agent_actions), reward, np.array(agent_state_next), np.array(swap_next_world_state), done)\n",
    "    #print(agent_state_next)\n",
    "\n",
    "    return experience\n",
    " \n",
    "\n",
    "def extract_data_from_dict(current_state, action, reward, next_state, done):\n",
    "\n",
    "    equipments = {\"none\":1, 'air':2, 'wooden_axe':3, 'wooden_pickaxe':4, \n",
    "              'stone_axe':5, 'stone_pickaxe':6, 'iron_axe':7, 'iron_pickaxe':8}\n",
    "\n",
    "\n",
    "    # current state\n",
    "    mainhand = current_state['equipped_items']['mainhand']\n",
    "    inventory = current_state['inventory']\n",
    "    pov = current_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    #flat_list = [item for sublist in agent_state for item in sublist]\n",
    "    vertical_agent_state = [np.vstack(item) for item in agent_state]\n",
    "    concat_agent_state = np.concatenate(vertical_agent_state, axis=1)\n",
    "    #print(concat_agent_state)\n",
    "    #[print(item.shape) for item in pov]\n",
    "    \n",
    "    swap_world_state = [np.swapaxes(item,0,2) for item in pov]\n",
    "    \n",
    "    #[print(item.shape) for item in swap_world_state]   \n",
    "    \n",
    "    vertical_world_state = np.stack(swap_world_state, axis=0)\n",
    "    #print(vertical_world_state.shape)\n",
    "    \n",
    "    #[print(item.shape) for item in vertical_world_state] \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # next_state\n",
    "    mainhand = next_state['equipped_items']['mainhand']\n",
    "    inventory = next_state['inventory']\n",
    "    pov = next_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    #flat_list = [item for sublist in agent_state for item in sublist]\n",
    "    vertical_next_agent_state = [np.vstack(item) for item in agent_state]\n",
    "    concat_next_agent_state = np.concatenate(vertical_next_agent_state, axis=1)\n",
    "\n",
    "    swap_next_world_state = [np.swapaxes(item,0,2) for item in pov]\n",
    "    \n",
    "    #[print(item.shape) for item in swap_world_state]   \n",
    "    \n",
    "    vertical_next_world_state = np.stack(swap_next_world_state, axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    # get action list\n",
    "    \n",
    "    cam_0 = action[\"camera\"][:,0]\n",
    "    cam_1 = action[\"camera\"][:,1]\n",
    "    \n",
    "    \n",
    "    agent_actions = []\n",
    "    agent_actions.append(action[\"attack\"])\n",
    "    agent_actions.append(action[\"back\"])\n",
    "    agent_actions.append(cam_0)\n",
    "    agent_actions.append(cam_1)\n",
    "    agent_actions.append(action[\"craft\"])\n",
    "    agent_actions.append(action[\"equip\"])\n",
    "    agent_actions.append(action[\"forward\"])\n",
    "    agent_actions.append(action[\"jump\"])\n",
    "    agent_actions.append(action[\"left\"])\n",
    "    agent_actions.append(action[\"nearbyCraft\"])\n",
    "    agent_actions.append(action[\"nearbySmelt\"])\n",
    "    agent_actions.append(action[\"place\"])\n",
    "    agent_actions.append(action[\"right\"])\n",
    "    agent_actions.append(action[\"sneak\"])\n",
    "    agent_actions.append(action[\"sprint\"])\n",
    "    \n",
    "\n",
    "    \n",
    "    vertical_agent_actions = [np.vstack(item) for item in agent_actions]\n",
    "    concat_agent_actions = np.concatenate(vertical_agent_actions, axis=1)\n",
    "\n",
    "    experiences = zip(concat_agent_state, vertical_world_state, concat_agent_actions, reward, concat_next_agent_state, vertical_next_world_state, done)\n",
    "\n",
    "    experiences = np.array(list(experiences))\n",
    "    return experiences\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minerl\n",
    "import logging\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from importlib import reload\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ddpg_agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "import ddpg_agent\n",
    "reload(ddpg_agent)\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#pil_img = transforms.ToPILImage()(pov)\n",
    "#imshow(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MineRLObtainDiamondDense-v0\") \n",
    "\n",
    "obs = env.reset()\n",
    "action = env.action_space.sample()\n",
    "\n",
    "mainhand_a = obs['equipped_items']['mainhand']\n",
    "inventory_a = obs['inventory']\n",
    "pov_a = obs['pov']\n",
    "\n",
    "agent_state_s = len(list(mainhand.values())) + len(list(inventory.values()))\n",
    "world_state_s = pov.shape\n",
    "action_s = len(list(action.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainhand_a = obs['equipped_items']['mainhand']\n",
    "inventory_a = obs['inventory']\n",
    "pov_a = obs['pov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "data = minerl.data.make(\n",
    "    'MineRLObtainDiamondDense-v0',\n",
    "    data_dir=\"/home/desin/minerl/data\")\n",
    "\n",
    "agent = Agent(agent_state_size=21, world_state_size=(64, 64, 3), action_size=14, random_seed=0)\n",
    "action_list =[]\n",
    "action_list_names = (\"attack\", \"back\", \"camera_0\", \"camera_1\", \"craft\", \"equip\",\n",
    "                     \"forward\", \"jump\", \"left\", \"nearbyCraft\", \"nearbySmelt\", \n",
    "                     \"place\", \"right\", \"sneak\", \"sprint\")\n",
    "agent_state_list_names = ['damage', 'maxDamage', 'type', 'coal', 'cobblestone', 'crafting_table', \n",
    "                    'dirt', 'furnace','iron_axe', 'iron_ingot', 'iron_ore', 'iron_pickaxe', \n",
    "                    'log', 'planks', 'stick', 'stone', 'stone_axe', 'stone_pickaxe', \n",
    "                    'torch', 'wooden_axe', 'wooden_pickaxe']\n",
    "agent_state_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through a single epoch gathering sequences of at most 32 steps\n",
    "i=0\n",
    "done_1=False\n",
    "active_reward=0\n",
    "for current_state, action, reward, next_state, done \\\n",
    "    in data.sarsd_iter(num_epochs=10, max_sequence_len=32):\n",
    "        i = i+1\n",
    "        done = np.delete(done, -1)\n",
    "        experiences = extract_data_from_dict(current_state, action, reward, next_state, done)\n",
    "        agent.learn_from_players(experiences)\n",
    "        \n",
    "        if (np.any(reward)):\n",
    "            print(\"reward...{} \".format(active_reward))\n",
    "        \n",
    "        if (done_1==False):\n",
    "            action_1, action_1_raw, agent_state_raw = agent.act(mainhand_a, inventory_a, pov_a)\n",
    "            obs_1, reward_1, done_1, info = env.step(action_1)\n",
    "            \n",
    "            action_list.append(action_1_raw.numpy())\n",
    "            agent_state_list.append(agent_state_raw)\n",
    "            \n",
    "            #pyplot.scatter(\"nnnn\", [sublist[0] for sublist in action_list])\n",
    "                        \n",
    "            #x = [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]\n",
    "            #print(x)\n",
    "\n",
    "            if (i%10==0):\n",
    "                for xe, ye in zip(action_list_names, [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]):\n",
    "                    \n",
    "                    pyplot.scatter([xe] * len(ye), ye)\n",
    "                    pyplot.show()\n",
    "                    #print(xe)\n",
    "                    #print(ye)\n",
    "            \n",
    "            if (reward_1 >0):\n",
    "                active_reward = active_reward+1\n",
    "                print(\"REWARD !!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        else:\n",
    "            obs_1 = env.reset()\n",
    "            done_1=False\n",
    "            print(\"RESET ----------------\")\n",
    "\n",
    "        #action_1 = env.action_space.sample()\n",
    "        #print(action_1)\n",
    "        #experience = extract_data_from_dict_single(obs_a, action_1, reward_1, obs_1, done_1)\n",
    "        #agent.add_memory(experience)\n",
    "\n",
    "        obs_a = obs_1\n",
    "        mainhand_a = obs_a['equipped_items']['mainhand']\n",
    "        inventory_a = obs_a['inventory']\n",
    "        pov_a = obs_a['pov']\n",
    "\n",
    "        env.render()\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAAHWCAYAAAAb7obyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu4bWddH/rvL3vngqCJmI0EknRTiyANJMCCRlEa8RBBLkprCNRb6DnuY+Ug4ZTThwg0SSkN1aOGgooJRVApkKC0gSAXAykICKxcSQg3Y0iCETZqkEuTQPL2jzHWzmTtdd1Z75rr8vk8z372HO8cc8zfO+a4fecYc6xqrQUAAADW2kHTLgAAAICtSeAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhiZ4+JHnnkkW337t09Jg0AAMAUXXbZZV9ure1aybhdAufu3bszOzvbY9IAAABMUVV9fqXjuqQWAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC6WDZxV9ZCqunLi3z9U1enrURwAAACb187lRmitfTrJCUlSVTuSfCHJ2zrXBbDlXPCyF+ema67aN3zMccfnmS99+RQrApLk/u+/cr+2v/nRE6ZQCcDWs9pLan8syV+21j7foxiArWp+2EySm665Khe87MVTqghIFg6bS7UDsDqrDZzPSvKmHoUAbGXzw+Zy7QAAW8GKA2dVHZLk6UkuXOT5PVU1W1Wze/fuXav6AAAA2KRWc4bzyUkub619caEnW2vntdZmWmszu3btWpvqAAAA2LRWEzifHZfTAhyQY447flXtAABbwYoCZ1XdO8kTk/xJ33IAtqZnvvTl+4VLd6mF6VvsbrTuUguwNqq1tuYTnZmZabOzs2s+XQAAAKarqi5rrc2sZNzV3qUWAAAAVkTgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoYudKRqqqI5K8NslxSVqSf91a+0jPwgAAYNXOOTa5/St3Dx96eHLGjdOrB7a5lZ7hfGWSd7XWHprk+CTX9SsJAAAOwPywmQzD5xw7nXqA5c9wVtXhSR6f5LQkaa3dkeSOvmUBAMAqzQ+by7UD3a3kDOeDkuxN8vtVdUVVvbaq7j1/pKraU1WzVTW7d+/eNS8UAACAzWUlgXNnkkcl+d3W2iOTfD3Ji+aP1Fo7r7U201qb2bVr1xqXCQAAwGazksB5c5KbW2sfHYffmiGAAgDAxnHo4atrB7pbNnC21v4myU1V9ZCx6ceSfLJrVQAAsFpn3Lh/uHSXWpiqFf1ZlCTPS/LGqjokyfVJntOvJAAAOEDCJWwoKwqcrbUrk8x0rgUAAIAtZKV/hxMAAABWReAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALrYuZKRquqGJF9NcmeSb7XWZnoWBbAVveo5p+aOb3x93/Ah33HvPO/33zLFigC2oHOOTW7/yt3Dhx6enHHj9OqBbW41Zzh/tLV2grAJsHrzw2aS3PGNr+dVzzl1ShUBbEHzw2YyDJ9z7HTqAVxSC7Ae5ofN5doBOADzw+Zy7UB3Kw2cLcl7quqyqtqz0AhVtaeqZqtqdu/evWtXIQAAAJvSSgPnD7fWHpXkyUmeW1WPnz9Ca+281tpMa21m165da1okAAAAm8+KAmdr7Qvj/19K8rYkj+1ZFMBWc8h33HtV7QAcgEMPX1070N2ygbOq7l1V3zn3OMnJSa7pXRjAVvK833/LfuHSXWoB1tgZN+4fLt2lFqZqJX8W5XuTvK2q5sb/b621d3WtCmALEi4B1oFwCRvKsoGztXZ9kuPXoRYAAAC2EH8WBQAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgi50rHbGqdiSZTfKF1tpT+5UEbDfnnX5pvnnbXfuGDz7soOw596TpFQQAwJpYzRnO5ye5rlchwPY0P2wmyTdvuyvnnX7pdAoCAGDNrChwVtXRSZ6S5LV9ywG2m/lhc7l2AAA2j5We4Tw3yb9LsugRYFXtqarZqprdu3fvmhQHAADA5rVs4Kyqpyb5UmvtsqXGa62d11qbaa3N7Nq1a80KBAAAYHNayRnOxyV5elXdkOTNSZ5QVX/UtSpg2zj4sIU3Q4u1AwCweSx7RNdaO6O1dnRrbXeSZyV5X2vtZ7tXBmwLe849ab9w6S61AABbw4r/LApAL8IlAMDWtKrA2Vq7NMmlXSoBAABgS/EjKQAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALnYuN0JVHZbkA0kOHcd/a2vtzN6FAdvHeadfmm/edte+4YMPOyh7zj1pegUBALAmVnKG8/YkT2itHZ/khCRPqqoT+5YFbBfzw2aSfPO2u3Le6ZdOpyAAANbMsmc4W2stydfGwYPHf61nUcD2MT9sLtcOAMDmsaLfcFbVjqq6MsmXkry3tfbRBcbZU1WzVTW7d+/eta4TAACATWZFgbO1dmdr7YQkRyd5bFUdt8A457XWZlprM7t27VrrOgEAANhkVnWX2tbarUnen+RJfcoBtpuDD1t4M7RYOwAAm8eyR3RVtauqjhgf3yvJE5N8qndhwPaw59yT9guX7lILALA1LHvToCRHJXlDVe3IEFAvaK29o29ZwHYiXAIAbE0ruUvt1UkeuQ61AAAAsIX4kRQAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBc7lxuhqo5J8gdJvjdJS3Jea+2VvQsDAGDt7H7Rxfu13fCKp0yhEmA7WckZzm8l+bettYclOTHJc6vqYX3LAgBgrSwUNpdqB1grywbO1totrbXLx8dfTXJdkgf2LgwAAIDNbVW/4ayq3UkemeSjCzy3p6pmq2p27969a1MdAAAAm9aKA2dV3SfJHyc5vbX2D/Ofb62d11qbaa3N7Nq1ay1rBAAAYBNaUeCsqoMzhM03ttb+pG9JAAAAbAXLBs6qqiT/Ncl1rbXf7F8SAABrabG70bpLLdDbsn8WJcnjkvxckk9U1ZVj26+21t7ZrywAANaScAlMw7KBs7X250lqHWoBAABgC1nVXWoBAABgpQROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6EDgBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQOAEAAOhC4AQAAKCLncuNUFWvS/LUJF9qrR3Xv6R+dr/o4v3abnjFU6ZQSWfnHJvc/pW7hw89PDnjxunVA2wrN7/og/u1Hf2KH5lCJX2dddZZK2rbzC553/ft1/ZjT/jLKVQCTHr4Gx6+X9snfuETU6ikr1vOPju3XnBhcuedyY4dOeKZp+SoM8+cdlms0krOcL4+yZM619HdQmFzqfZNa37YTIbhc46dTj3AtrJQ2FyqfbNaLFhupcC5UNhcqh1YHwuFzaXaN6tbzj47t77pzUPYTJI778ytb3pzbjn77OkWxqotGzhbax9I8nfrUAtrYX7YXK4dAAA2mFsvuHBV7Wxca/YbzqraU1WzVTW7d+/etZosAACw3cyd2VxpOxvWmgXO1tp5rbWZ1trMrl271mqyAADAdrNjx+ra2bDcpXarOfTw1bUDAMAGc8QzT1lVOxvXtgmci92NdsvdpfaMG/cPl+5SC6yTxe5Gu9XuUrsdbhq02N1o3aUWpmuxu9FutbvUHnXmmTni2c+6+4zmjh054tnPcpfaTahaa0uPUPWmJCclOTLJF5Oc2Vr7r0u9ZmZmps3Ozq5VjQAAAGwQVXVZa21mJeMu+3c4W2vPvuclAQAAsN1sm0tqAQAAWF8CJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJ5vWxddfnJPfenIe8YZH5OS3npyLr7942iUBAAATdk67ADgQF19/cc768Fm57c7bkiS3fP2WnPXhs5IkT/nHT5liZQAAwBxnONmUXnn5K/eFzTm33XlbXnn5K6dUEQAAMJ/AyaZ0y9dvWVU7AACw/gROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC4ETgAAALoQONmUTn3IqatqBwAA1t/OaRcAB+IlJ74kSXLhZy7MXe2uHFQH5ZTvP2VfOwAAMH3VWlvzic7MzLTZ2dk1ny4AAADTVVWXtdZmVjKuS2oBAADoQuAEAACgC4ETAACALgROAAAAuhA4AQAA6ELgBAAAoAuBEwAAgC52rmSkqnpSklcm2ZHkta21V3StinvmnGOT279y9/Chhydn3Di9eoAkyQUve3FuuuaqfcPHHHd8nvnSl0+xIgDYuK576A/s1/YDn7puCpX09du/9L792p77midMoZI+lj3DWVU7kvx2kicneViSZ1fVw3oXxgGaHzaTYficY6dTD5Bk/7CZJDddc1UueNmLp1QRAGxcC4XNpdo3q4XC5lLtm9FKLql9bJLPtdaub63dkeTNSX6yb1kcsPlhc7l2YF3MD5vLtQMAbAUrCZwPTHLTxPDNY9u3qao9VTVbVbN79+5dq/oAAADYpNbspkGttfNaazOttZldu3at1WQBAADYpFYSOL+Q5JiJ4aPHNjaiQw9fXTuwLo457vhVtQMAbAUrCZwfT/LgqnpQVR2S5FlJLupbFgfsjBv3D5fuUgtT98yXvny/cOkutQCwsMXuRrvV7lK72N1ot9Jdaqu1tvxIVT+R5NwMfxblda21JY+QZmZm2uzs7NpUCNvYLWefnVsvuDC5885kx44c8cxTctSZZ067LAAAtrGquqy1NrOScVf0dzhba+9M8s57VBWwKrecfXZufdOb72648859w0InAACbwZrdNAhYW98WNlfQDgAAG43ACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJG9TOBzxgVe0AALDRCJywQd3vBaenDjvs29rqsMNyvxecPqWKAABgdXZOuwA4UL/47l/MX/zNX+wbPvH+J+b8Hz9/ihWtrcOf9rQkyZd+69x865ZbsvOoo3K/F5y+rx0AADa6aq2t+URnZmba7Ozsmk8X5swPm3O2WugEAICNpqoua63NrGRcl9SyKS0UNpdqBwAA1p/ACQAAQBcCJwAAAF0InAAAAHQhcLIpnXj/E1fVDgAArD+Bk03p/B8/f79w6Q61AACwsfg7nGxawiUAAGxsznACAADQhcAJAABAFwInAAAAXQicAAAAdCFwAgAA0IXACQAAQBcCJwAAAF0InAAAAHQhcAIAANCFwAkAAEAXAicAAABdCJwAAAB0IXACAADQhcAJAABAFwInAAAAXVRrbe0nWrU3yefXfMJr58gkX552EetAP7eO7dDHRD+3Gv3cOrZDHxP93Gq2Qz+3Qx8T/dyI/lFrbddKRuwSODe6qpptrc1Mu47e9HPr2A59TPRzq9HPrWM79DHRz61mO/RzO/Qx0c/NziW1AAAAdCFwAgAA0MV2DZznTbuAdaKfW8d26GOin1uNfm4d26GPiX5uNduhn9uhj4l+bmrb8jecAAAA9Lddz3ACAADQmcAJAABAF1sucFbVr048PqKqfvkeTOv1VfXTa1PZ2qiq3VV1zT2cxklV9Y61qmmrqMF/qarPVdXVVfWoade01qrqoVX1kaq6vapeOO16VqKq3jR+Hi+oqtOq6gHTrqmHqnpAVb112nUkSVX9SlVdV1VvnHIdp1XVq6f03h+exvtOU1V9bQXj7Fs2xn3JD61HbWvpQJarqvr+qnpnVX22qi6vqguq6ntXOY11mXer7V9VHTTu+66pqk9U1cer6kFrUMe+45WqOqGqfuKeTnOR97m0qrbcn5GYb1z+jlhmnAXnRc/5v5FslePbqnp6Vb1omXF2V9W/Wq+a7qktFziT/OrE4yOSHHDgZHOrqp2rfMmTkzx4/Lcnye+ueVFr7AD6+HdJfiXJ/9+hnAOyVB+q6v5JHtNae0Rr7beSnJZkSwbO1tpft9Y2yhdcv5zkia21n1luxANYBhebTlXVhtkntdY2XZBaJ5PLxklJNtV8OpDltaoOS3Jxkt9trT24tfaoJL+TZNe88Zabdvd5d4Dr46kZtquPaK09PMkzkty6poUlJyTZ8oGnl6qqJE9trR3o52L+bxJVtbO1dlFr7RXLjLo7icC5Hqrqv1fVZVV1bVXtqapXJLlXVV05fjP/iiTfNw7/elXdp6ouGb+d/ERV/eTEtH5+PItyVVX94QLv9bLxjOeOdeziYnaO35BeV1VvrarvqKp/P34reU1VnTdunFJV/6Sq/mzs1+VV9X2TE6qqx1TVFfPb19r8+VtVT6uqj47v/Wdz3xRX1VlV9Yaq+mBVfb6q/kVV/dr4eb2rqg4ex3t0Vf3P8fN/d1UdNbZfWlXnVtVskucv9j6L+Mkkf9AGf5HkiLnpbpU+tta+1Fr7eJJvrrRfa2GBefP6qnpNVX00ya9V1WNrOPN6RVV9uKoeMr70PUkeOK7DL00yk+SN4/C91rMPS6mqn62qj411/V5V7aiq51TVZ8b282s841Dzrpyo8axSffvZgNOq6n+Mn/Vnq+rMdezLa5L84yR/WlX/tobt7NVV9RdV9YhxnLPGz/FDSf6wqi6eeO6Kqvr34+P/UFW/WItse8c+f7qq/iDJNUmOmZxvSR63Xv2er6q+VvO+La+qV1fVaePjG6rqnPEzn62qR43r6V9W1S+N45xUVR8Y58+nx2V+U+x3q+r/q2GfcnVVnT22TS4bL0jyS0leMM6DH+lQw+4a9nPn17Cff09V3auqvm/cVl42bkcfOo6/1DZ33/I6Tv6Y+evXuLyePvH+L6+q52c4qPtIa+3tc8+11i5trV0zrqsXVdX7klyyxLK+0Lx7YVXdVlVvn3L/jkpyS2vtrrFvN7fW/n4c52s1HD9dO77nY8fpXl9VTx/H2TGOM7e8/N/zPsdDkvyHJKeOy8qp92B5+FTNO/6ZN87vjuvjtXPL7dj+mBr2LVfVsE3+zuXqnrbaf/t4Z1UdOT730vG5P6/hKqDJK5ZOGfv4mar6kbWa/2ulqu49bhOvquGY9dQatqdnT6w3D50Y93Vjf66ob993fHAc//Ja4GqBWqfj28Us0c+5472PVdU/Gcedf0y07yqF8bn/Mi6/19fdxw+vSPIj42f6gmn0cVVaa5v2X5L7jv/fK8PK+D1Jvjbx/O4k10wM70zyXePjI5N8Lkkl+adJPpPkyHnTfX2Sn07y60lek/GuvlPu8+4kLcnjxuHXJXnhXM1j2x8medr4+KNJnjE+PizJd2T4ZvUdGb5dvSzJsZ1r3m/+JvnuufmZ5P9K8hvj47OS/HmSg5Mcn+QbSZ48Pve2JD81PvfhJLvG9lOTvG58fGmS35l47wXfZ5E635HkhyeGL0kys5X6OPGas5K8cJ2W2YXmzevH+b1jbPuuJDvHx/9Hkj+eWN4n1+FLV/qZrNe/JD+Q5O1JDh6HfyfJLyS5McMZkEOSfCjJq8fnX5/kpyde/7X5fc1wJveWDNu0ue3buvU7yQ0ZtpGvSnLm2PaEJFdOLD+XJbnXOPyiJM9NcniSjyd599j+/iQPyeLb3t1J7kpy4vjcUYvNtyl8rl/LuK2caHt1ktMm5tG/GR//VpKrk3znWPsXx/aTktyWIWjsSPLeyc9+o/2bWBZPznBr/srwxfQ7kjx+ctmYWA66bUfG5eNbSU4Yhy9I8rMZts0PHtv+WZL3jY+X2uZOLq8Lrl/j+10+jnNQkr8cx/nNJM9fpMbTktycu48bFlzWF5l3L98g/Tt6rO3KJL+R5JET/Wv59v3Te3L3vmtue7AnyUvGx4cmmU3yoOy/TbtH63IWP/65NOP2ceJz2DG2PyLDtuT6DFfLJOP+ZrG6p70ezuvv5PbxhnGZesz4WR2WYZvz2Yzr4djnueXiJ5L82VrN/zXs179Mcv7E8OFj3543Dv9ykteOj/9Tkp8dHx+R4Vji3hmOZQ8b2x+cZHZ8fFLW8fj2APv54nH45zPuX7L/MdG+z2t87sIM6+zDknxusq/T/jxX+m9NLoWaol+pqmeMj4/JsNAtpZL8p6p6fIaV+IFJvjfDgdSFrbUvJ0lr7e8mXvPSJB9tre1Z08rvmZtaax8aH/9Rhksk/6qq/l2GlfC+Sa6tqkuTPLC19rYkaa3dliQ1nPz8gQwHFCe31v66c737zd+qeniSt9Rw1u6QJH81Mf6ftta+WVWfyLDTeNfY/okMG+CHJDkuyXvHvuzIsHOd85aJx0cv8T5raTv08UAtNG8ytt05jnN4kjdU1YMzHFAcPJVKD8yPJXl0ko+P/bpXhp3dpa21vUlSVW9J8v2rnO57W2t/O77+T5L8cIYDovX0wxl2mmmtva+qvqeqvmt87qLW2v8aH38w43Yow6WHTxzPPDyotfbpGs7aL7TtTZLPt+GKgmQ4uL6n8209XTT+/4kk92mtfTXJV2v4jfTcb60+1lq7Phl+j5xhnm6I3+ou4eTx3xXj8H0y7F8/MIVa/qq1duX4+LIM28cfSnLhuL4lQ1hIlt4WTi6vyQLrV2vt3Kr626p6ZIbl84rW2t9OvM9i3jtx3LDYccbfbNT+jeM8JMO2+gkZztSe0lq7JMkd+fb90+0T+67dY/vJSR4xcebl8AzLy2cWnWMHbqHjn0nPrKo9GQLlURkO0FuGM7gfT5LW2j8kSVUtVvdG2odObh/nPC7J/xiP6W6rqrfPe/5Pxv/nlqeN5hNJfqOq/nOGwPTBcVmfrPtfjI9PTvL0iTO4hyU5NslfJ3l1VZ2Q5M58+35iPY9vl7JYP980Pv+mDF9Wzpk8Jprvv7fhCoRP1ip/O75RbNrAWVUnZTgT8oOttW+M4eqwZV72Mxm+fX70uMG8YQWv+XiSR1fVfecF0WlqCwz/ToZv+G6qqrOyfL9uGcd5ZIYVd729KslvttYuGj/Lsyaeuz1JWmt3VdU32/hVToad984MO/RrW2s/uMi0v76bGPSpAAAGSUlEQVTC95nvCxm+uJhz9Nh2oDZiHzeSyT68LMn7W2vPqKrdGb6l3SwqyRtaa2fsa6j6qdy9w5zvWxl/zlDD5ZWHLDLeQuv5RjL5+X08wxmU6zOcxTsyyS9mOHBIlt72Tk5no9n3WY3mb1dvH/+/a+Lx3PDc/nWjf44LqSTntNZ+b9qF5Nvn650ZgtKtrbUTFhh3qW3h/OVssc/ltRnOLtw/wxm0JLk2yT9fosbJaa/2OGMj9C+ttduT/GmGS36/mOFKm0uSzN8/Te675pbxynB26t2Tbzhuy9faoutTDTc6emGGM5l/X1Wvz9LzfsG6N5gD2T7OLVN3ZgMe57fWPlPDTRl/Isl/rKpLxqcWqruS/MvW2qcnpzEe534xw5n2gzJcSTJn2se3SZbs5+QyPPl4qc96cjux7DdgG9Gm+C3JIg5P8vdj2HxokhPH9m+O36YnyVczXG4w+ZovjTuBH03yj8b292W45v17kqSq7jvxmndluE764qqanNY0HVtVc0HkX2W4PDNJvlxV98lwGXDGb9tvHg9+U1WH1t2/d7g1yVOSnDPuuHpaaP4enrvD3C+scnqfTrJrbh5U1cFV9U8XGXc173NRkp+vwYlJvtJau2WZ18zZLH2chqXWrzmTfThtiWnNX6c3gkuS/HRV3S/Z178rkvzz8YzgwUlOmRj/hgxnRJPk6Vn8bO4Tq+q+NfxW9acyXF663j6Y4QB67ku+L8+dHZjUWrsjyU0Z+vmR8XUvzN1nxBbb9s730Sw+36bh80keNm47j8hwNnu1HltVDxq/XDg1d2+vN7J3J/nX4/4kVfXAueV7nmmsj/+Q4YqeU5J9N5s6fnxuNdvCxdavtyV5UobLFueCyH9L8kNV9ZS5F1fV46vquAWmu9Jl/asZLg2cev9q+P3xA8bHB2W4DPXzy0x/0ruT/Ju6+/4D319V8/u2VsvKYsc/yXCp7NeTfGU8C/Tksf3TSY6qqseM9X3nGJZXUvdG9KEkT6uqw8Z19KkreM2G2XeOy9o3Wmt/lOEna0v9RYB3J3le1b77kjxybD88d//u+OcyXAU2Zz2Pbxe1RD9Pnfj/I/fgLTbMZ7oSmzlwvivDzXOuyxAI5y45OC/J1VX1xvFSkQ/V8GPdX0/yxiQzNVwK8vNJPpUkrbVrM/yW4n9W1VUZfq+xT2vtwiTnJ7moNsaNSj6d5Llj3787w91Uz8/wO413ZzjbMOfnMlx6fHWG3wTef+6J1toXM2yofruq/lmvYheZv2dluGTosiRfXuX07sgQqv/zOL0rs/jd/lbzPu/McIbmcxnm54rvcLxZ+lhV96+qm5P8v0leUlU3192XSHax3Po1+rUMO4crsvQ3sq9P8praQDcNaq19MslLkrxnXM/em+FSrrMy7Ew+lOS6iZecnyFUXZXkB7P4t5ofS/LHGX4b+MettfW+nDYZ+vDosV+vyNIHuR/McKD9v8bHR4//J4tse+cbv+A5KwvPt/XWWms3Zfhd3TXj/1cs/ZIFfTzDbz+vy3Cp3tvWrMJOWmvvyRCyPjJ+Zm/Nwgc2b0/yjOp006Al/EyS/3Nch67NcMO3ZHXb3AXXr3Hb+/4kF8xd3jYu00/NcOD72ar6ZIb9w94FpruiZT3DvPvxDDc2nD/v1rV/Se6X5O013LTs6gxn9lfzZ2Nem+STSS4fp/F72X87/v4MX97c05vWLHT8kyRprV2VYR39VIbl90Nj+x0ZDu5fNc7T92Y4A7aSujec8dLgizJ8Vn+a4dLNryzzsrWa/2vh4Uk+VlVXJjkzyX9cYtyXZfhS9uqqunYcTsZ7JYyf50Mzbz+6Xse3y1isn9897lOfn+Se3Ozn6gw3krqqNsFNg+Z+fA5AJzXc2XSmtfb/9BiftTWejb+8tbbY2amVTuekDDfzWMkZCDaA8Qzf5UlOaa19dtr1rLXN3L8aLtF9R2ttoTPL20pV3ae19rUarlr7QJI9rbXLp10XS6vhEvuZuXtabCeb+QwnAKyp8TKoj2QD/a1a1kdVPSzDFS6XbLYwthJbvX/bzHnjmbPLM5zBFjbZ0JzhZNupqudkuJRh0odaa8+dRj09bIc+AgCw8QmcAAAAdOGSWgAAALoQOAEAAOhC4AQAAKALgRMAAIAuBE4AAAC6+N/bAGTCgZl9dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(action_list)\n",
    "#print(agent_state_list)\n",
    "fig= pyplot.figure(figsize=(6,3))\n",
    "fig.set_size_inches(16, 8)\n",
    "for xe, ye in zip(action_list_names, [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]):\n",
    "    pyplot.scatter([xe] * len(ye), ye)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.xticks([1, 2])\n",
    "plt.axes().set_xticklabels(['cat1', 'cat2'])\n",
    "\n",
    "plt.savefig('t.png')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "import ddpg_agent\n",
    "reload(ddpg_agent)\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "print(agent_state_s)\n",
    "print(world_state_s)\n",
    "print(action_s)\n",
    "\n",
    "agent = Agent(agent_state_size=agent_state_s, world_state_size=world_state_s, action_size=action_s, random_seed=0)\n",
    "\n",
    "\n",
    "def ddpg(n_episodes=5000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        obs = env.reset()\n",
    "        done = False        \n",
    "        agent.reset()\n",
    "        \n",
    "        mainhand = obs['equipped_items']['mainhand']\n",
    "        inventory = obs['inventory']\n",
    "        pov = obs['pov']\n",
    "\n",
    "        scores = []  \n",
    "        actions = []\n",
    "        \n",
    "        t = 0\n",
    "        while True:\n",
    "            \n",
    "            action, action_raw = agent.act(mainhand, inventory, pov)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "\n",
    "            n_mainhand = obs['equipped_items']['mainhand']\n",
    "            n_inventory = obs['inventory']\n",
    "            n_pov = obs['pov']\n",
    "            scores.append(reward)\n",
    "            if reward != 0.0:\n",
    "                print(reward)\n",
    "            \n",
    "            action_flat = agent.flatten_action(action_raw)\n",
    "\n",
    "            agent.step(mainhand, inventory, pov, action_flat, reward, n_mainhand, n_inventory, n_pov, done)\n",
    "\n",
    "            mainhand = n_mainhand \n",
    "            inventory = n_inventory \n",
    "            pov = n_pov\n",
    "            \n",
    "            env.render()\n",
    "            if np.any(done):                                  # exit loop if episode finished\n",
    "                break \n",
    "                \n",
    "        scores_avg = np.mean(scores)\n",
    "        scores_deque.append(scores_avg)\n",
    "        scores_all.append(scores_avg)\n",
    "        #print(scores_agents)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:2.3f}\\tScore: {:2.3f}       '.format(i_episode, np.mean(scores_deque), scores_avg), end=\"\")\n",
    "        if i_episode % 200 == 0:\n",
    "            print(agent.actor_scheduler.get_lr())\n",
    "            print('\\nEpisode {}\\tAverage Score: {:2.3f}\\tScore: {:2.3f}\\tBalls Over: {}       '.format(i_episode, np.mean(scores_deque), scores_avg, balls_over), end=\"\")\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{}.pth'.format(i_episode))\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{}.pth'.format(i_episode))   \n",
    "            \n",
    "    return scores_all\n",
    "\n",
    "#scores = ddpg(n_episodes=10, max_t=130)\n",
    "\n",
    "\n",
    "scores = ddpg()\n",
    "print('scores len  {}'.format(len(scores)))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "fig.savefig('AverageScore.png')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MineRL",
   "language": "python",
   "name": "minerl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
