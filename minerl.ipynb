{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_dict_single(current_state, action, reward, next_state, done):\n",
    "\n",
    "    equipments = {\"none\":1, 'air':2, 'wooden_axe':3, 'wooden_pickaxe':4, \n",
    "              'stone_axe':5, 'stone_pickaxe':6, 'iron_axe':7, 'iron_pickaxe':8}\n",
    "\n",
    "\n",
    "    # current state\n",
    "    mainhand = current_state['equipped_items']['mainhand']\n",
    "    inventory = current_state['inventory']\n",
    "    pov = current_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    \n",
    "    swap_world_state = np.swapaxes(pov,0,2)\n",
    "    \n",
    "     \n",
    "    # next_state\n",
    "    mainhand = next_state['equipped_items']['mainhand']\n",
    "    inventory = next_state['inventory']\n",
    "    pov = next_state['pov']\n",
    "\n",
    "\n",
    "    agent_state_next = []\n",
    "    agent_state_next.append(mainhand['damage'])\n",
    "    agent_state_next.append(mainhand['maxDamage'])\n",
    "    agent_state_next.append(mainhand['type'])\n",
    "    agent_state_next.append(inventory['coal'])\n",
    "    agent_state_next.append(inventory['cobblestone'])\n",
    "    agent_state_next.append(inventory['crafting_table'])\n",
    "    agent_state_next.append(inventory['dirt'])\n",
    "    agent_state_next.append(inventory['furnace'])\n",
    "    agent_state_next.append(inventory['iron_axe'])\n",
    "    agent_state_next.append(inventory['iron_ingot'])\n",
    "    agent_state_next.append(inventory['iron_ore'])\n",
    "    agent_state_next.append(inventory['iron_pickaxe'])\n",
    "    agent_state_next.append(inventory['log'])\n",
    "    agent_state_next.append(inventory['planks'])\n",
    "    agent_state_next.append(inventory['stick'])\n",
    "    agent_state_next.append(inventory['stone'])\n",
    "    agent_state_next.append(inventory['stone_axe'])\n",
    "    agent_state_next.append(inventory['stone_pickaxe'])\n",
    "    agent_state_next.append(inventory['torch'])\n",
    "    agent_state_next.append(inventory['wooden_axe'])\n",
    "    agent_state_next.append(inventory['wooden_pickaxe'])\n",
    "\n",
    " \n",
    "    swap_next_world_state = np.swapaxes(pov,0,2)\n",
    "    \n",
    "\n",
    "    \n",
    "    # get action list\n",
    "    \n",
    "    agent_actions = []\n",
    "    agent_actions.append(action[\"attack\"])\n",
    "    agent_actions.append(action[\"back\"])\n",
    "    agent_actions.append(action[\"camera\"][0])\n",
    "    agent_actions.append(action[\"camera\"][1])\n",
    "    agent_actions.append(action[\"craft\"])\n",
    "    agent_actions.append(action[\"equip\"])\n",
    "    agent_actions.append(action[\"forward\"])\n",
    "    agent_actions.append(action[\"jump\"])\n",
    "    agent_actions.append(action[\"left\"])\n",
    "    agent_actions.append(action[\"nearbyCraft\"])\n",
    "    agent_actions.append(action[\"nearbySmelt\"])\n",
    "    agent_actions.append(action[\"place\"])\n",
    "    agent_actions.append(action[\"right\"])\n",
    "    agent_actions.append(action[\"sneak\"])\n",
    "    agent_actions.append(action[\"sprint\"])\n",
    "    \n",
    "\n",
    "\n",
    "    experience = (np.array(agent_state), np.array(swap_world_state), np.array(agent_actions), reward, np.array(agent_state_next), np.array(swap_next_world_state), done)\n",
    "    #print(agent_state_next)\n",
    "\n",
    "    return experience\n",
    " \n",
    "\n",
    "def extract_data_from_dict(current_state, action, reward, next_state, done):\n",
    "\n",
    "    equipments = {\"none\":1, 'air':2, 'wooden_axe':3, 'wooden_pickaxe':4, \n",
    "              'stone_axe':5, 'stone_pickaxe':6, 'iron_axe':7, 'iron_pickaxe':8}\n",
    "\n",
    "\n",
    "    # current state\n",
    "    mainhand = current_state['equipped_items']['mainhand']\n",
    "    inventory = current_state['inventory']\n",
    "    pov = current_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    #flat_list = [item for sublist in agent_state for item in sublist]\n",
    "    vertical_agent_state = [np.vstack(item) for item in agent_state]\n",
    "    concat_agent_state = np.concatenate(vertical_agent_state, axis=1)\n",
    "    #print(concat_agent_state)\n",
    "    #[print(item.shape) for item in pov]\n",
    "    \n",
    "    swap_world_state = [np.swapaxes(item,0,2) for item in pov]\n",
    "    \n",
    "    #[print(item.shape) for item in swap_world_state]   \n",
    "    \n",
    "    vertical_world_state = np.stack(swap_world_state, axis=0)\n",
    "    #print(vertical_world_state.shape)\n",
    "    \n",
    "    #[print(item.shape) for item in vertical_world_state] \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # next_state\n",
    "    mainhand = next_state['equipped_items']['mainhand']\n",
    "    inventory = next_state['inventory']\n",
    "    pov = next_state['pov']\n",
    "\n",
    "\n",
    "    agent_state = []\n",
    "    agent_state.append(mainhand['damage'])\n",
    "    agent_state.append(mainhand['maxDamage'])\n",
    "    agent_state.append(mainhand['type'])\n",
    "    agent_state.append(inventory['coal'])\n",
    "    agent_state.append(inventory['cobblestone'])\n",
    "    agent_state.append(inventory['crafting_table'])\n",
    "    agent_state.append(inventory['dirt'])\n",
    "    agent_state.append(inventory['furnace'])\n",
    "    agent_state.append(inventory['iron_axe'])\n",
    "    agent_state.append(inventory['iron_ingot'])\n",
    "    agent_state.append(inventory['iron_ore'])\n",
    "    agent_state.append(inventory['iron_pickaxe'])\n",
    "    agent_state.append(inventory['log'])\n",
    "    agent_state.append(inventory['planks'])\n",
    "    agent_state.append(inventory['stick'])\n",
    "    agent_state.append(inventory['stone'])\n",
    "    agent_state.append(inventory['stone_axe'])\n",
    "    agent_state.append(inventory['stone_pickaxe'])\n",
    "    agent_state.append(inventory['torch'])\n",
    "    agent_state.append(inventory['wooden_axe'])\n",
    "    agent_state.append(inventory['wooden_pickaxe'])\n",
    "\n",
    "    #flat_list = [item for sublist in agent_state for item in sublist]\n",
    "    vertical_next_agent_state = [np.vstack(item) for item in agent_state]\n",
    "    concat_next_agent_state = np.concatenate(vertical_next_agent_state, axis=1)\n",
    "\n",
    "    swap_next_world_state = [np.swapaxes(item,0,2) for item in pov]\n",
    "    \n",
    "    #[print(item.shape) for item in swap_world_state]   \n",
    "    \n",
    "    vertical_next_world_state = np.stack(swap_next_world_state, axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    # get action list\n",
    "    \n",
    "    cam_0 = action[\"camera\"][:,0]\n",
    "    cam_1 = action[\"camera\"][:,1]\n",
    "    \n",
    "    \n",
    "    agent_actions = []\n",
    "    agent_actions.append(action[\"attack\"])\n",
    "    agent_actions.append(action[\"back\"])\n",
    "    agent_actions.append(cam_0)\n",
    "    agent_actions.append(cam_1)\n",
    "    agent_actions.append(action[\"craft\"])\n",
    "    agent_actions.append(action[\"equip\"])\n",
    "    agent_actions.append(action[\"forward\"])\n",
    "    agent_actions.append(action[\"jump\"])\n",
    "    agent_actions.append(action[\"left\"])\n",
    "    agent_actions.append(action[\"nearbyCraft\"])\n",
    "    agent_actions.append(action[\"nearbySmelt\"])\n",
    "    agent_actions.append(action[\"place\"])\n",
    "    agent_actions.append(action[\"right\"])\n",
    "    agent_actions.append(action[\"sneak\"])\n",
    "    agent_actions.append(action[\"sprint\"])\n",
    "    \n",
    "\n",
    "    \n",
    "    vertical_agent_actions = [np.vstack(item) for item in agent_actions]\n",
    "    concat_agent_actions = np.concatenate(vertical_agent_actions, axis=1)\n",
    "\n",
    "    experiences = zip(concat_agent_state, vertical_world_state, concat_agent_actions, reward, concat_next_agent_state, vertical_next_world_state, done)\n",
    "\n",
    "    experiences = np.array(list(experiences))\n",
    "    return experiences\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minerl\n",
    "import logging\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from importlib import reload\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ddpg_agent import Agent\n",
    "#%matplotlib inline\n",
    "\n",
    "import ddpg_agent\n",
    "reload(ddpg_agent)\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#pil_img = transforms.ToPILImage()(pov)\n",
    "#imshow(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MineRLObtainDiamondDense-v0\") \n",
    "\n",
    "obs = env.reset()\n",
    "action = env.action_space.sample()\n",
    "\n",
    "mainhand_a = obs['equipped_items']['mainhand']\n",
    "inventory_a = obs['inventory']\n",
    "pov_a = obs['pov']\n",
    "\n",
    "agent_state_s = len(list(mainhand.values())) + len(list(inventory.values()))\n",
    "world_state_s = pov.shape\n",
    "action_s = len(list(action.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainhand_a = obs['equipped_items']['mainhand']\n",
    "inventory_a = obs['inventory']\n",
    "pov_a = obs['pov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "data = minerl.data.make(\n",
    "    'MineRLObtainDiamondDense-v0',\n",
    "    data_dir=\"/home/desin/minerl/data\")\n",
    "\n",
    "agent = Agent(agent_state_size=21, world_state_size=(64, 64, 3), action_size=14, random_seed=0)\n",
    "action_list =[]\n",
    "action_list_names = (\"attack\", \"back\", \"camera_0\", \"camera_1\", \"craft\", \"equip\",\n",
    "                     \"forward\", \"jump\", \"left\", \"nearbyCraft\", \"nearbySmelt\", \n",
    "                     \"place\", \"right\", \"sneak\", \"sprint\")\n",
    "agent_state_list_names = ['damage', 'maxDamage', 'type', 'coal', 'cobblestone', 'crafting_table', \n",
    "                    'dirt', 'furnace','iron_axe', 'iron_ingot', 'iron_ore', 'iron_pickaxe', \n",
    "                    'log', 'planks', 'stick', 'stone', 'stone_axe', 'stone_pickaxe', \n",
    "                    'torch', 'wooden_axe', 'wooden_pickaxe']\n",
    "agent_state_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through a single epoch gathering sequences of at most 32 steps\n",
    "i=0\n",
    "done_1=False\n",
    "active_reward=0\n",
    "for current_state, action, reward, next_state, done \\\n",
    "    in data.sarsd_iter(num_epochs=10, max_sequence_len=32):\n",
    "        i = i+1\n",
    "        done = np.delete(done, -1)\n",
    "        experiences = extract_data_from_dict(current_state, action, reward, next_state, done)\n",
    "        agent.learn_from_players(experiences)\n",
    "        \n",
    "        if (np.any(reward)):\n",
    "            print(\"reward...{} \".format(active_reward))\n",
    "        \n",
    "        if (done_1==False):\n",
    "            action_1, action_1_raw, agent_state_raw = agent.act(mainhand_a, inventory_a, pov_a)\n",
    "            obs_1, reward_1, done_1, info = env.step(action_1)\n",
    "            \n",
    "            action_list.append(action_1_raw.numpy())\n",
    "            agent_state_list.append(agent_state_raw)\n",
    "            \n",
    "            #pyplot.scatter(\"nnnn\", [sublist[0] for sublist in action_list])\n",
    "                        \n",
    "            #x = [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]\n",
    "            #print(x)\n",
    "\n",
    "            if (i%10==0):\n",
    "                for xe, ye in zip(action_list_names, [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]):\n",
    "                    \n",
    "                    pyplot.scatter([xe] * len(ye), ye)\n",
    "                    pyplot.show()\n",
    "                    #print(xe)\n",
    "                    #print(ye)\n",
    "            \n",
    "            if (reward_1 >0):\n",
    "                active_reward = active_reward+1\n",
    "                print(\"REWARD !!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        else:\n",
    "            obs_1 = env.reset()\n",
    "            done_1=False\n",
    "            print(\"RESET ----------------\")\n",
    "\n",
    "        #action_1 = env.action_space.sample()\n",
    "        #print(action_1)\n",
    "        #experience = extract_data_from_dict_single(obs_a, action_1, reward_1, obs_1, done_1)\n",
    "        #agent.add_memory(experience)\n",
    "\n",
    "        obs_a = obs_1\n",
    "        mainhand_a = obs_a['equipped_items']['mainhand']\n",
    "        inventory_a = obs_a['inventory']\n",
    "        pov_a = obs_a['pov']\n",
    "\n",
    "        env.render()\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(action_list)\n",
    "#print(agent_state_list)\n",
    "fig= pyplot.figure(figsize=(6,3))\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "for xe, ye in zip(action_list_names, [[(action_list[li])[0,ci]  for li in range(len(action_list))] for ci in range(len(action_list_names)) ]):\n",
    "    pyplot.scatter([xe] * len(ye), ye)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.xticks([1, 2])\n",
    "plt.axes().set_xticklabels(['cat1', 'cat2'])\n",
    "\n",
    "plt.savefig('t.png')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "import ddpg_agent\n",
    "reload(ddpg_agent)\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "print(agent_state_s)\n",
    "print(world_state_s)\n",
    "print(action_s)\n",
    "\n",
    "agent = Agent(agent_state_size=agent_state_s, world_state_size=world_state_s, action_size=action_s, random_seed=0)\n",
    "\n",
    "\n",
    "def ddpg(n_episodes=5000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        obs = env.reset()\n",
    "        done = False        \n",
    "        agent.reset()\n",
    "        \n",
    "        mainhand = obs['equipped_items']['mainhand']\n",
    "        inventory = obs['inventory']\n",
    "        pov = obs['pov']\n",
    "\n",
    "        scores = []  \n",
    "        actions = []\n",
    "        \n",
    "        t = 0\n",
    "        while True:\n",
    "            \n",
    "            action, action_raw = agent.act(mainhand, inventory, pov)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "\n",
    "            n_mainhand = obs['equipped_items']['mainhand']\n",
    "            n_inventory = obs['inventory']\n",
    "            n_pov = obs['pov']\n",
    "            scores.append(reward)\n",
    "            if reward != 0.0:\n",
    "                print(reward)\n",
    "            \n",
    "            action_flat = agent.flatten_action(action_raw)\n",
    "\n",
    "            agent.step(mainhand, inventory, pov, action_flat, reward, n_mainhand, n_inventory, n_pov, done)\n",
    "\n",
    "            mainhand = n_mainhand \n",
    "            inventory = n_inventory \n",
    "            pov = n_pov\n",
    "            \n",
    "            env.render()\n",
    "            if np.any(done):                                  # exit loop if episode finished\n",
    "                break \n",
    "                \n",
    "        scores_avg = np.mean(scores)\n",
    "        scores_deque.append(scores_avg)\n",
    "        scores_all.append(scores_avg)\n",
    "        #print(scores_agents)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:2.3f}\\tScore: {:2.3f}       '.format(i_episode, np.mean(scores_deque), scores_avg), end=\"\")\n",
    "        if i_episode % 200 == 0:\n",
    "            print(agent.actor_scheduler.get_lr())\n",
    "            print('\\nEpisode {}\\tAverage Score: {:2.3f}\\tScore: {:2.3f}\\tBalls Over: {}       '.format(i_episode, np.mean(scores_deque), scores_avg, balls_over), end=\"\")\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{}.pth'.format(i_episode))\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{}.pth'.format(i_episode))   \n",
    "            \n",
    "    return scores_all\n",
    "\n",
    "#scores = ddpg(n_episodes=10, max_t=130)\n",
    "\n",
    "\n",
    "scores = ddpg()\n",
    "print('scores len  {}'.format(len(scores)))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "fig.savefig('AverageScore.png')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MineRL",
   "language": "python",
   "name": "minerl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
